/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import { expect, test } from "vitest";
import { Pipeshub } from "../index.js";
import { createTestHTTPClient } from "./test-client.js";

test("Crawling Jobs Schedule Crawling Job Daily Sync", async () => {
  const testHttpClient = createTestHTTPClient("scheduleCrawlingJob-dailySync");

  const pipeshub = new Pipeshub({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: testHttpClient,
    security: {
      bearerAuth: "<YOUR_BEARER_TOKEN_HERE>",
    },
  });

  const result = await pipeshub.crawlingJobs.scheduleCrawlingJob({
    connector: "drive",
    connectorId: "507f1f77bcf86cd799439011",
    body: {
      scheduleConfig: {
        scheduleType: "daily",
        isEnabled: true,
        timezone: "UTC",
        hour: 2,
        minute: 0,
      },
    },
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    success: true,
    message: "Crawling job scheduled successfully",
    data: {
      jobId: "crawl-drive-507f1f77bcf86cd799439011-507f1f77bcf86cd799439012",
      connector: "drive",
      connectorId: "507f1f77bcf86cd799439011",
      scheduleConfig: {
        scheduleType: "daily",
        isEnabled: true,
        timezone: "UTC",
        hour: 2,
        minute: 0,
      },
      scheduledAt: new Date("2024-01-15T10:30:00Z"),
    },
  });
});

test("Crawling Jobs Schedule Crawling Job Hourly Sync", async () => {
  const testHttpClient = createTestHTTPClient("scheduleCrawlingJob-hourlySync");

  const pipeshub = new Pipeshub({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: testHttpClient,
    security: {
      bearerAuth: "<YOUR_BEARER_TOKEN_HERE>",
    },
  });

  const result = await pipeshub.crawlingJobs.scheduleCrawlingJob({
    connector: "drive",
    connectorId: "507f1f77bcf86cd799439011",
    body: {
      scheduleConfig: {
        scheduleType: "hourly",
        isEnabled: true,
        timezone: "America/New_York",
        minute: 30,
        interval: 4,
      },
      priority: 3,
      maxRetries: 5,
    },
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    success: true,
    message: "Crawling job scheduled successfully",
    data: {
      jobId: "crawl-drive-507f1f77bcf86cd799439011-507f1f77bcf86cd799439012",
      connector: "drive",
      connectorId: "507f1f77bcf86cd799439011",
      scheduleConfig: {
        scheduleType: "daily",
        isEnabled: true,
        timezone: "UTC",
        hour: 2,
        minute: 0,
      },
      scheduledAt: new Date("2024-01-15T10:30:00Z"),
    },
  });
});

test("Crawling Jobs Schedule Crawling Job Weekly Sync", async () => {
  const testHttpClient = createTestHTTPClient("scheduleCrawlingJob-weeklySync");

  const pipeshub = new Pipeshub({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: testHttpClient,
    security: {
      bearerAuth: "<YOUR_BEARER_TOKEN_HERE>",
    },
  });

  const result = await pipeshub.crawlingJobs.scheduleCrawlingJob({
    connector: "drive",
    connectorId: "507f1f77bcf86cd799439011",
    body: {
      scheduleConfig: {
        scheduleType: "weekly",
        isEnabled: true,
        timezone: "Europe/London",
        daysOfWeek: [
          1,
          3,
          5,
        ],
        hour: 3,
        minute: 0,
      },
    },
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    success: true,
    message: "Crawling job scheduled successfully",
    data: {
      jobId: "crawl-drive-507f1f77bcf86cd799439011-507f1f77bcf86cd799439012",
      connector: "drive",
      connectorId: "507f1f77bcf86cd799439011",
      scheduleConfig: {
        scheduleType: "daily",
        isEnabled: true,
        timezone: "UTC",
        hour: 2,
        minute: 0,
      },
      scheduledAt: new Date("2024-01-15T10:30:00Z"),
    },
  });
});

test("Crawling Jobs Schedule Crawling Job Custom Cron", async () => {
  const testHttpClient = createTestHTTPClient("scheduleCrawlingJob-customCron");

  const pipeshub = new Pipeshub({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: testHttpClient,
    security: {
      bearerAuth: "<YOUR_BEARER_TOKEN_HERE>",
    },
  });

  const result = await pipeshub.crawlingJobs.scheduleCrawlingJob({
    connector: "drive",
    connectorId: "507f1f77bcf86cd799439011",
    body: {
      scheduleConfig: {
        scheduleType: "custom",
        isEnabled: true,
        timezone: "UTC",
        cronExpression: "0 */6 * * *",
        description: "Every 6 hours",
      },
    },
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    success: true,
    message: "Crawling job scheduled successfully",
    data: {
      jobId: "crawl-drive-507f1f77bcf86cd799439011-507f1f77bcf86cd799439012",
      connector: "drive",
      connectorId: "507f1f77bcf86cd799439011",
      scheduleConfig: {
        scheduleType: "daily",
        isEnabled: true,
        timezone: "UTC",
        hour: 2,
        minute: 0,
      },
      scheduledAt: new Date("2024-01-15T10:30:00Z"),
    },
  });
});

test("Crawling Jobs Schedule Crawling Job One Time Sync", async () => {
  const testHttpClient = createTestHTTPClient(
    "scheduleCrawlingJob-oneTimeSync",
  );

  const pipeshub = new Pipeshub({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: testHttpClient,
    security: {
      bearerAuth: "<YOUR_BEARER_TOKEN_HERE>",
    },
  });

  const result = await pipeshub.crawlingJobs.scheduleCrawlingJob({
    connector: "drive",
    connectorId: "507f1f77bcf86cd799439011",
    body: {
      scheduleConfig: {
        scheduleType: "once",
        isEnabled: true,
        timezone: "UTC",
        scheduledTime: new Date("2024-12-25T10:00:00Z"),
      },
      priority: 1,
    },
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    success: true,
    message: "Crawling job scheduled successfully",
    data: {
      jobId: "crawl-drive-507f1f77bcf86cd799439011-507f1f77bcf86cd799439012",
      connector: "drive",
      connectorId: "507f1f77bcf86cd799439011",
      scheduleConfig: {
        scheduleType: "daily",
        isEnabled: true,
        timezone: "UTC",
        hour: 2,
        minute: 0,
      },
      scheduledAt: new Date("2024-01-15T10:30:00Z"),
    },
  });
});

test("Crawling Jobs Schedule Crawling Job", async () => {
  const testHttpClient = createTestHTTPClient("scheduleCrawlingJob");

  const pipeshub = new Pipeshub({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: testHttpClient,
    security: {
      bearerAuth: "<YOUR_BEARER_TOKEN_HERE>",
    },
  });

  const result = await pipeshub.crawlingJobs.scheduleCrawlingJob({
    connector: "drive",
    connectorId: "507f1f77bcf86cd799439011",
    body: {
      scheduleConfig: {
        scheduleType: "once",
        isEnabled: true,
        timezone: "UTC",
        scheduledTime: new Date("2024-12-25T10:00:00Z"),
      },
    },
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    success: true,
    message: "Crawling job scheduled successfully",
    data: {
      jobId: "crawl-drive-507f1f77bcf86cd799439011-507f1f77bcf86cd799439012",
      connector: "drive",
      connectorId: "507f1f77bcf86cd799439011",
      scheduleConfig: {
        scheduleType: "daily",
        isEnabled: true,
        timezone: "UTC",
        hour: 2,
        minute: 0,
      },
      scheduledAt: new Date("2024-01-15T10:30:00Z"),
    },
  });
});

test("Crawling Jobs Get Crawling Job Status", async () => {
  const testHttpClient = createTestHTTPClient("getCrawlingJobStatus");

  const pipeshub = new Pipeshub({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: testHttpClient,
    security: {
      bearerAuth: "<YOUR_BEARER_TOKEN_HERE>",
    },
  });

  const result = await pipeshub.crawlingJobs.getCrawlingJobStatus({
    connector: "drive",
    connectorId: "507f1f77bcf86cd799439011",
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    success: true,
    message: "Job status retrieved successfully",
    data: {
      id: "crawl-drive-507f1f77bcf86cd799439011-507f1f77bcf86cd799439012",
      name: "crawl-drive-507f1f77bcf86cd799439011",
      data: {
        connector: "drive",
        connectorId: "507f1f77bcf86cd799439011",
        scheduleConfig: {
          scheduleType: "hourly",
          isEnabled: true,
          timezone: "UTC",
          minute: 30,
          interval: 1,
        },
        orgId: "507f1f77bcf86cd799439012",
        userId: "507f1f77bcf86cd799439013",
        timestamp: new Date("2024-11-06T06:42:05.632Z"),
      },
      delay: 3600000,
      timestamp: 1703520000000,
      attemptsMade: 0,
      failedReason: null,
      state: "waiting",
    },
  });
});

test("Crawling Jobs Remove Crawling Job", async () => {
  const testHttpClient = createTestHTTPClient("removeCrawlingJob");

  const pipeshub = new Pipeshub({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: testHttpClient,
    security: {
      bearerAuth: "<YOUR_BEARER_TOKEN_HERE>",
    },
  });

  const result = await pipeshub.crawlingJobs.removeCrawlingJob({
    connector: "drive",
    connectorId: "507f1f77bcf86cd799439011",
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    success: true,
    message: "Crawling job removed successfully",
  });
});
